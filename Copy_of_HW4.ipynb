{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DotBion/techgb2336-dataSciBiz/blob/main/Copy_of_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Movie Reviews for Text and Sentiment Analysis\n",
        "\n",
        "The data in this homework is 20k movie reviews which have been already labelled as positive or negative.   We will apply our text toolbox to see if we can fit an effective supervised model.\n",
        "\n",
        "The Movie Review data can be [downloaded from this link](https://drive.google.com/uc?export=download&id=1UA9CyRd8y7Wi4RKruXfItXadT3hY92bE)"
      ],
      "metadata": {
        "id": "_ypdf9zqV-4X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "woeBvsx-xIiu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in movie_reviews.csv\n",
        "url = 'https://www.google.com/url?q=https%3A%2F%2Fdrive.google.com%2Fuc%3Fexport%3Ddownload%26id%3D1UA9CyRd8y7Wi4RKruXfItXadT3hY92bE'\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "z1zcpUzkxMk6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "86cda9e5-b87e-4665-ea37-10f5f8bca2eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  I grew up (b. 1965) watching and loving the Th...      0\n",
              "1  When I put this movie in my DVD player, and sa...      0\n",
              "2  Why do people who do not know what a particula...      0\n",
              "3  Even though I have great interest in Biblical ...      0\n",
              "4  Im a die hard Dads Army fan and nothing will e...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a711d93-9293-45b8-9e7b-b55b28ed9b88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When I put this movie in my DVD player, and sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why do people who do not know what a particula...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Even though I have great interest in Biblical ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a711d93-9293-45b8-9e7b-b55b28ed9b88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a711d93-9293-45b8-9e7b-b55b28ed9b88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a711d93-9293-45b8-9e7b-b55b28ed9b88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9ab267c3-4edc-4b1b-9b62-a842f5f6bc35\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ab267c3-4edc-4b1b-9b62-a842f5f6bc35')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9ab267c3-4edc-4b1b-9b62-a842f5f6bc35 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 19999,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19932,\n        \"samples\": [\n          \"Full marks for Pacino's rendering of the speech over the dead kid's coffin; Shakespeare's Mark Antony would be put to shame!!<br /><br />Was it Paul Schrader or was it Ken Lipper who should be complimented on the remarkable dialogues? They are rich and intelligent and well worth your time if you like movies with good scripts. I found the story narrative developing quite well right up to the voice-over postscript.<br /><br />There is little else to talk about in this film; even John Cusack has done better roles than this one. Interestingly, the film is very male oriented--the women are mere appendages.\",\n          \"I saw this recently and I must say, I was moved by the factual basis of the story. However, \\\"Holly\\\" as a movie did not quite work. I am however, looking forward to watching the documentary which the producers who organised this project had made because I think that would be a much more compelling work than this film.<br /><br />The international cast was composed of B-class actors but their acting was appropriate, and I must give a special mention for the young actress who played Holly. This was her first movie role and she did a very nice job, considering hers is the most challenging part. <br /><br />Ron Livingston was adequate but bland as Patrick, the American whose quest is to \\\"save\\\" Holly, but Chris Penn was good in this, his final role. Unfortunately, despite my mostly favourable opinion of Virginie Ledoyen and Udo Kier, both of these actors were very much forgettable and did not do their best work in this film.<br /><br />I believe in the film's message and intention, but I have to be fair, so I rate \\\"Holly\\\" 3 stars based on its shortcomings as a movie. But I think the subject matter deserves serious consideration and I am pleased that the people behind this movie have made a documentary as well which I hope will have its debut on BBC and other TV networks.\",\n          \"Oh boy, where do I go with this one? Herendous acting, weak plot, stupid deaths, pointless nudity...<br /><br />This isn't entertainment...this is hell.<br /><br />Hell.<br /><br />Don't waste your money, time, or life on this pit of evil.<br /><br />It's just...god damn is this movie awful! Tom Savini, WHY?! Why would you waste your life on this crap? This movie not worth it. I'd rather snort crack and smash my head up against a wall than watch THIS...this sinful act again!<br /><br />Please take my advice and stay the f#@k away from this elephant turd of a film. No, you know what? I shouldn't even have to call this thing a film! Just stay AWAY!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is simply a full text review, and a rating of 0(bad) or 1(good), determined by a human labeller.\n",
        "\n",
        "\n",
        "We need to remove HTML tags...you can run the following code to remove them."
      ],
      "metadata": {
        "id": "4_h2CDGY_6Ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove html tags\n",
        "df['text'] = df['text'].apply(lambda x: re.sub('<[^<]+?>', '', x))"
      ],
      "metadata": {
        "id": "9quM9CWvyhLz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Lets do all of the things we need to do to prepare text data.  Lemmatize, tokenize, removing stopwords and punctuation.  Feel free to grab the exact code from the `T8_SOTU` notebook (specifically the function `clean_text`) and run it.   Create a new field called \"clean_review\" and append it to your data frame, so that you retain the original text in one feature, and have the cleaned text in another feature. This will allow us to go back and look at the original text of the review when we are evaluating the model**"
      ],
      "metadata": {
        "id": "qh0PDu9Fzwwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "# Download the missing 'punkt_tab' resource\n",
        "nltk.download('punkt_tab') # This line was added to download the missing resource\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # remove punctuation\n",
        "    tokens = word_tokenize(text.lower()) # tokenize and lower\n",
        "    tokens = [w for w in tokens if not w in stop_words] # remove stopwords\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens] # lemmatize\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['clean_review'] = df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "cNIGo2kWZq2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a873843-5145-4419-8dba-f62da117aedf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_review']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "4nt8pW8GEuGZ",
        "outputId": "79ab0e84-1d28-4ea8-9f0a-340943c4e209"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        grew b 1965 watching loving thunderbird mate s...\n",
              "1        put movie dvd player sat coke chip expectation...\n",
              "2        people know particular time past like feel nee...\n",
              "3        even though great interest biblical movie bore...\n",
              "4        im die hard dad army fan nothing ever change g...\n",
              "                               ...                        \n",
              "19994    movie stuffed full stock horror movie goody ch...\n",
              "19995    required watch movie work didnt pay contrary g...\n",
              "19996    white noise potential one talked movie since e...\n",
              "19997    five deadly venom great kungfu action movie wr...\n",
              "19998    ali g indahouse got one funniest film ive seen...\n",
              "Name: clean_review, Length: 19999, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>grew b 1965 watching loving thunderbird mate s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>put movie dvd player sat coke chip expectation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>people know particular time past like feel nee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>even though great interest biblical movie bore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>im die hard dad army fan nothing ever change g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19994</th>\n",
              "      <td>movie stuffed full stock horror movie goody ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>required watch movie work didnt pay contrary g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>white noise potential one talked movie since e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>five deadly venom great kungfu action movie wr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>ali g indahouse got one funniest film ive seen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19999 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Split data into training and test.  Run a TFIDF Vectorizer on the cleaned reviews - you need to `fit` the Vectorizer to the training data, and then `transform` both the training and the test sets using the vectorizer.  Review our T8 notebooks for syntax.**"
      ],
      "metadata": {
        "id": "tdGQArCVAroH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# Use 'label' instead of 'rating' for the target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_review'], df['label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize and fit TF-IDF vectorizer to the training data\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the fitted vectorizer\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "x_XkoXWZZrAr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Fit your favorite classification model to the training set - you can use Logistic Regression (but be sure to regularlize!), or something more complex like XGBoost or Random Forests, or any other classification model.  Apply your model to the test set and report the AUC.**"
      ],
      "metadata": {
        "id": "40UahMbWZ1wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Initialize and train a Logistic Regression model with regularization\n",
        "logreg = LogisticRegression(C=0.1, solver='liblinear') # C is the inverse of regularization strength\n",
        "logreg.fit(X_train_vec, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_prob = logreg.predict_proba(X_test_vec)[:, 1]\n",
        "\n",
        "# Calculate the AUC\n",
        "auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(f\"AUC: {auc}\")\n"
      ],
      "metadata": {
        "id": "qKdzmAtXaMkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50efa5b-4586-45d6-968c-e40231b1459a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9278907166451156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize and train an XGBoost classifier\n",
        "import xgboost as xgb\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "xgb_model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_prob_xgb = xgb_model.predict_proba(X_test_vec)[:, 1]\n",
        "\n",
        "# Calculate the AUC for XGBoost\n",
        "auc_xgb = roc_auc_score(y_test, y_pred_prob_xgb)\n",
        "print(f\"XGBoost AUC: {auc_xgb}\")\n"
      ],
      "metadata": {
        "id": "T9WlnW_ApLD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29834600-c8b0-4c4f-9a89-72d10972aec9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost AUC: 0.9295540481483593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Find the P(label=1) for all cases in the test set.  Identify the review in the test set which has the _lowest_ probability of being a good review BUT has label=1 (good).  This is an error!  Print the complete original review text for this error.  Do you think this is actually a good or bad review?  Do you think this error is due to an error in the labelling (y_test) or a problem with the model?  Explain.**"
      ],
      "metadata": {
        "id": "xYYbSnplLbe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming y_pred_prob contains probabilities from the better performing model (e.g., XGBoost if it has a better AUC)\n",
        "min_prob_idx = np.argmin(y_pred_prob_xgb[y_test == 1])\n",
        "min_prob = y_pred_prob_xgb[y_test == 1][min_prob_idx]\n",
        "error_review_index = y_test[y_test == 1].index[min_prob_idx]\n",
        "error_review_original = df['text'][error_review_index]\n",
        "\n",
        "print(f\"Review with lowest probability of being good (but labeled good):\")\n",
        "print(f\"Probability: {min_prob}\")\n",
        "print(f\"Original review text:\\n{error_review_original}\")\n",
        "\n",
        "print(\"\\nIs this actually a good or bad review?\")\n",
        "#  (Your subjective opinion based on reading the review)\n",
        "# Example:\n",
        "print(\"Based on the review, I think it is (good/bad).\")  # Replace (good/bad) with your assessment\n",
        "\n",
        "\n",
        "print(\"\\nIs this error due to a labeling error or a problem with the model?\")\n",
        "# (Your explanation of the potential source of the error)\n",
        "# Example:\n",
        "print(\"The error seems to be due to a potential labeling issue. While the model assigns a very low probability to this review, \")\n",
        "print(\"the review itself, however, expresses some positive sentiments, but may be expressed less strongly, with other more negative aspects presented.\")\n",
        "print(\"The human labeler might have interpreted a slight positive aspect as a good review, while the model might be more sensitive to the subtle nuances and negative cues present in the review.\")\n"
      ],
      "metadata": {
        "id": "bRZ6-tsabDWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d8dec8-10fa-4a54-9685-1934e14f8549"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review with lowest probability of being good (but labeled good):\n",
            "Probability: 0.0025764082092791796\n",
            "Original review text:\n",
            "**SPOILERS AHEAD**It is really unfortunate that a movie so well produced turns out to besuch a disappointment. I thought this was full of (silly) clichés andthat it basically tried to hard. To the (American) guys out there: how many of you spend yourtime jumping on your girlfriend's bed and making monkeysounds? To the (married) girls: how many of you have suddenlygone from prudes to nymphos overnight--but not with yourhusband? To the French: would you really ask about someonebeing \"à la fac\" when you know they don't speak French? Wouldn'tyou use a more common word like \"université\"? I lived in France for a while and I sort of do know and understandEurope (and I love it), but my (German) roommate and I found thispretty insulting overall. It looked like a movie funded by theEuropean Parliament, and it tried too hard basically. It had allsorts of differences that it tried to tie together (not a bad thing initself) but the result is at best awkward, but in fact ridiculous--toomany clashes that wouldn't really happen. Then the end of themovie--the last 10 minutes--ruined all the rest. Why doesn't Xaviertalk to the Erasmus students he meets back in Paris? Why doeshe just walk off? Why does he just run away from his job, is that\"freedom\"? And in the end, is the new Europe supposed to rest ona bunch of people who smoke up and shag all day? Is this whatit's made up of? Besides, the acting was pretty horrible. I can't believe JudithGodrèche's role and acting. Why was she made to look likeEmanuelle Béart so much? At first I thought Xavier was OK butwith retrospect I think he was pretty bad. And that's all really too bad, because technically (opening credits,scenes when he's asking what papers he needs) it was reallygood (except for sound editing around the British siblings), and thesoundtrack was great too. So the form was good, but the contentpretty horrible.\n",
            "\n",
            "Is this actually a good or bad review?\n",
            "Based on the review, I think it is (good/bad).\n",
            "\n",
            "Is this error due to a labeling error or a problem with the model?\n",
            "The error seems to be due to a potential labeling issue. While the model assigns a very low probability to this review, \n",
            "the review itself, however, expresses some positive sentiments, but may be expressed less strongly, with other more negative aspects presented.\n",
            "The human labeler might have interpreted a slight positive aspect as a good review, while the model might be more sensitive to the subtle nuances and negative cues present in the review.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) To get an objective view of whether this review is _really_ positive or negative, we can use a pre-defined sentiment model built off of an existing lexicon.  One such model is called Vader.  [documentation here](https://medium.com/@rslavanyageetha/vader-a-comprehensive-guide-to-sentiment-analysis-in-python-c4f1868b0d2e).  Using your incorrectly labelled review from the last probem and the Vader code below, report what the negativity score is from Vader ('neg' in the output). Does this support your conclusion about the error above?**"
      ],
      "metadata": {
        "id": "-RYXMzk1bEjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk # Added this line\n",
        "\n",
        "# Download the VADER lexicon\n",
        "nltk.download('vader_lexicon') # Added this line\n",
        "\n",
        "# Assuming 'error_review_original' contains the text of the misclassified review\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "scores = analyzer.polarity_scores(error_review_original)\n",
        "print(scores)\n",
        "neg_score = scores['neg']\n",
        "print(f\"\\nNegativity score from Vader: {neg_score}\")\n",
        "\n",
        "print(\"\\nDoes this support your conclusion about the error above?\")\n",
        "# Your analysis here. Example:\n",
        "print(\"The negativity score from VADER helps support the conclusion about the error. If the score is high,\")\n",
        "print(\"it lends credence to the idea that the model's low probability prediction and my assessment as bad\")\n",
        "print(\" are more likely correct, and thus the original label is likely in error.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAXxdz_1F1VP",
        "outputId": "fc3f34df-dcd4-45f6-aa2c-2dc518c32bf9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.103, 'neu': 0.789, 'pos': 0.108, 'compound': 0.5735}\n",
            "\n",
            "Negativity score from Vader: 0.103\n",
            "\n",
            "Does this support your conclusion about the error above?\n",
            "The negativity score from VADER helps support the conclusion about the error. If the score is high,\n",
            "it lends credence to the idea that the model's low probability prediction and my assessment as bad\n",
            " are more likely correct, and thus the original label is likely in error.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "text = ## YOUR REVIEW TEXT HERE ##\n",
        "scores = analyzer.polarity_scores(text)\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "PXqLUKmi9CRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6) `eli5` is a Python library that tries to \"explain\" machine learning models.  It works for simple models like logistic regression as well as more complicated, black box models like XGBoost and Random Forests.   Look up the documentation for `eli5` and use it to show the words contributing most to positive and negative scores in your model.**"
      ],
      "metadata": {
        "id": "jFoS_EjoOtyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install eli5\n",
        "\n",
        "import eli5\n",
        "\n",
        "# Assuming 'logreg' is your trained logistic regression model and 'vectorizer' is your TFIDF vectorizer\n",
        "eli5.show_weights(logreg, vec=vectorizer)\n",
        "\n",
        "# Assuming 'xgb_model' is your trained XGBoost model\n",
        "eli5.show_weights(xgb_model, vec=vectorizer)\n"
      ],
      "metadata": {
        "id": "9gvPquELTC-n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "6b9a4a43-42c1-44a7-ff1e-3a7d1d25da58"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eli5\n",
            "  Downloading eli5-0.16.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.11/dist-packages (from eli5) (25.3.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from eli5) (3.1.6)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from eli5) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from eli5) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from eli5) (1.6.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from eli5) (0.20.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from eli5) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.0->eli5) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->eli5) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->eli5) (3.6.0)\n",
            "Downloading eli5-0.16.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.4/108.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: eli5\n",
            "Successfully installed eli5-0.16.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0182\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waste\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.49%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0175\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                worst\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 84.25%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0129\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                bad\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 85.12%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0119\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                awful\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 85.74%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0112\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                boring\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 86.25%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0106\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                crap\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 87.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0091\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                supposed\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 87.71%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0091\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wonderful\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0080\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lame\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.93%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0078\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                worse\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 89.05%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0077\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                terrible\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.14%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0066\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                poorly\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.21%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0065\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wasted\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0065\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                superb\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0065\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                excellent\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.26%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0065\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                nothing\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.75%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0060\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                stupid\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0056\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                instead\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.68%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0052\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                loved\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0051\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                horrible\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.78%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 100575 more &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}